import numpy as np
import torch
import torch.nn.functional as F
from torch.distributions.categorical import Categorical

def softmax(x):
    exp = np.exp(x)
    return exp / np.sum(exp, axis=0, keepdims=True)

def generate_sequence_grid_world(model, gw, batches, device):
    """Generate sequence of states generated by the model's policy"""

    model.eval()
    max_iterations = gw.states

    x = torch.tensor(gw.get_start_state(batches)).to(device)
    generated_actions = []
    tgt = [(torch.ones(batches, 1) * gw.SOS).to(device)]
    rewards = []
    acts = []

    for i in range(gw.states):
        tgt_in = torch.cat(tgt, dim=1).to(torch.int32)
        policy = F.softmax(model(x, tgt_in, -1), dim=-1)[:,-1,:]
        distrib = Categorical(policy)
        actions = distrib.sample()
        acts.append(actions)
        actions= actions.cpu().numpy()
        state_mdp = x.cpu().numpy()
        if len(tgt) > 1:
            state_mdp = tgt[-1].cpu().numpy()

        #print(state_mdp)

        x_next, r, _ = gw.batched_step(state_mdp, actions)
        x_next = torch.tensor(x_next).to(device).unsqueeze(1)

        rewards.append(torch.tensor(r).to(device))
        tgt.append(x_next)

    tgt = torch.cat(tgt, dim=1)
    rewards = torch.stack(rewards, dim=1)
    acts = torch.stack(acts, dim=1)
    return x, tgt, rewards, acts




